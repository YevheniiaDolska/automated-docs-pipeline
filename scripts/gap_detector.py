#!/usr/bin/env python3
"""Compatibility wrapper for unified documentation gap detection.

Canonical implementation lives in `scripts.gap_detection`.
This script is kept for backward compatibility and for tools that still call:

- `python3 scripts/gap_detector.py`
- `python3 scripts/gap_detector.py --json`
- `python3 scripts/gap_detector.py --create-issues`
"""

from __future__ import annotations

import argparse
import contextlib
import io
import json
import subprocess
import sys
from dataclasses import asdict
from datetime import datetime
from pathlib import Path
from typing import Any

ROOT_DIR = Path(__file__).resolve().parents[1]
if str(ROOT_DIR) not in sys.path:
    sys.path.insert(0, str(ROOT_DIR))

try:
    from scripts.gap_detection.gap_aggregator import GapAggregator
except ModuleNotFoundError:
    # Fallback for direct execution environments with different module paths.
    from gap_detection.gap_aggregator import GapAggregator


def _compute_debt_score(gaps: list[dict[str, Any]]) -> dict[str, Any]:
    """Build a lightweight debt score compatible with legacy output."""
    weights = {"high": 5, "medium": 3, "low": 1}
    by_priority = {"high": 0, "medium": 0, "low": 0}

    for gap in gaps:
        priority = str(gap.get("priority", "low")).lower()
        if priority not in by_priority:
            priority = "low"
        by_priority[priority] += 1

    total_score = sum(by_priority[p] * weights[p] for p in by_priority)
    total_gaps = len(gaps)

    if total_score < 50:
        risk_level = "low"
    elif total_score < 150:
        risk_level = "medium"
    else:
        risk_level = "high"

    return {
        "total_score": total_score,
        "total_gaps": total_gaps,
        "by_priority": by_priority,
        "risk_level": risk_level,
    }


def _build_issue_body(gap: dict[str, Any]) -> str:
    title = gap.get("title", "Untitled gap")
    source = gap.get("source", "unknown")
    category = gap.get("category", "unknown")
    priority = gap.get("priority", "medium")
    description = gap.get("description", "")
    action = gap.get("action_required", "Review and update documentation")
    files = gap.get("related_files", []) or []

    location = "\n".join(f"- `{f}`" for f in files) if files else "N/A"

    return (
        "## Documentation Gap Detected\n\n"
        f"**Title:** {title}\n"
        f"**Priority:** {priority}\n"
        f"**Source:** {source}\n"
        f"**Category:** {category}\n\n"
        "### Description\n"
        f"{description}\n\n"
        "### Related Files\n"
        f"{location}\n\n"
        "### Recommended Action\n"
        f"{action}\n\n"
        "---\n"
        "Generated by `scripts/gap_detector.py` compatibility wrapper."
    )


def _create_github_issues(gaps: list[dict[str, Any]], dry_run: bool = True) -> None:
    """Create up to 5 GitHub issues for high-priority gaps using GitHub CLI."""
    high_priority = [g for g in gaps if str(g.get("priority", "")).lower() == "high"]

    for gap in high_priority[:5]:
        title = f"[DOC-GAP] {gap.get('title', 'Untitled gap')}"
        body = _build_issue_body(gap)

        if dry_run:
            print("\n[DRY RUN] Would create issue")
            print(f"Title: {title}")
            print(f"Body preview: {body[:220]}...")
            continue

        subprocess.run(
            [
                "gh",
                "issue",
                "create",
                "--title",
                title,
                "--body",
                body,
                "--label",
                "documentation,auto-created,doc-gap",
            ],
            check=True,
        )
        print(f"Created issue: {title}")


def run_analysis(output_dir: str, since_days: int, algolia_csv: str | None, algolia_json: str | None) -> dict[str, Any]:
    """Run canonical gap analysis via modular `scripts.gap_detection` components."""
    aggregator = GapAggregator(output_dir=output_dir)
    report = aggregator.run_full_analysis(
        repo_path=".",
        since_days=since_days,
        algolia_csv=algolia_csv,
        algolia_json=algolia_json,
    )

    aggregator.save_to_json(report)
    aggregator.save_to_csv(report)
    try:
        aggregator.save_to_excel(report)
    except Exception:
        # Excel export is optional (depends on openpyxl runtime availability).
        pass

    gaps = [asdict(g) for g in report.gaps]
    debt_score = _compute_debt_score(gaps)

    return {
        "gaps": gaps,
        "summary": report.summary,
        "sources_analyzed": report.sources_analyzed,
        "debt_score": debt_score,
        "timestamp": datetime.now().isoformat(),
    }


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Unified Documentation Gap Detector (compatibility wrapper)")
    parser.add_argument("--json", action="store_true", help="Output results as JSON")
    parser.add_argument("--create-issues", action="store_true", help="Create GitHub issues for high-priority gaps")
    parser.add_argument("--dry-run", action="store_true", help="Do not create issues, print previews")
    parser.add_argument("--config", default=".gap-config.yml", help="Legacy option kept for compatibility")
    parser.add_argument("--since", type=int, default=7, help="Analyze commits from last N days")
    parser.add_argument("--output-dir", default="reports", help="Directory for generated reports")
    parser.add_argument("--algolia-csv", help="Optional path to Algolia CSV export")
    parser.add_argument("--algolia-json", help="Optional path to Algolia JSON export")
    return parser.parse_args()


def main() -> int:
    args = parse_args()

    # Keep legacy `--config` accepted without changing behavior.
    if args.config and not Path(args.config).exists():
        # Non-blocking warning to preserve old command compatibility.
        print(f"Warning: config file not found: {args.config}", file=sys.stderr)

    if args.json:
        # Ensure strict JSON output for programmatic consumers.
        with contextlib.redirect_stdout(io.StringIO()):
            result = run_analysis(
                output_dir=args.output_dir,
                since_days=args.since,
                algolia_csv=args.algolia_csv,
                algolia_json=args.algolia_json,
            )
    else:
        result = run_analysis(
            output_dir=args.output_dir,
            since_days=args.since,
            algolia_csv=args.algolia_csv,
            algolia_json=args.algolia_json,
        )

    if args.create_issues:
        _create_github_issues(result["gaps"], dry_run=args.dry_run)

    if args.json:
        print(json.dumps(result, indent=2, ensure_ascii=False))
    else:
        summary = result.get("summary", {})
        print("Gap analysis complete")
        print(f"Total gaps: {summary.get('total_gaps', len(result.get('gaps', [])))}")
        print(f"By source: {summary.get('by_source', {})}")
        print(f"By doc type: {summary.get('by_doc_type', {})}")
        print(f"Debt score: {result['debt_score']['total_score']} ({result['debt_score']['risk_level']})")

    return 0


if __name__ == "__main__":
    raise SystemExit(main())
